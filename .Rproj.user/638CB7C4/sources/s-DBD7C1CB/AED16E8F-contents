---
title: "RMP/AA Processing and Analysis Notebook"
author: "Dakota Murray"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

## Research Goals of First Paper:

- Outline an open and replicable methodology for the collecting, processing, merging, and re-processing data sources. 
- Understand the context and meaning of RMP scores, and how they can be interpreted
- Provide evidence for an answer to the question of "are research and teaching performance rated at U.S.
universities?"
- Provide evidence for an answer to the question of "Do moderating factors, such as gender, discipline, and university type play a role in the relationship between research and teaching performance?"
- Introduce this data source, providing summary plots and outlining the general shape of the data, especially as it relates to understnading the analysis of the previous two points
- Provide starting point for future papger that go deeper into statistical and text analysis

## TODO:

- Add *ALL* code here, starting from raw files, all the way to analysis. Make completely reproducible
- Include details on how data was collected
- Re-collect RMP data
- Re-do matching here, to make matching process explicit
- Calculate statistics for matching: how many matched? What percentage of each dataset?
- Manually validate RMP/AA data
- Check which gender data we are using, re-merge
- Manually validate gender assignment
- Calcualte reearch output at lower discipline level, report at high level. Do not even worry about the normalized values, these are too tricky with the highly skewed datasets
- Report comment and rating statistics for both matched and unmatched professors. Is there a major difference?
- Does different selection process for interdisciplinary analysis change the outcome of our analysis?
- Include extraction and processing of course numbers, validate to see how often they match to a propoer class
- scrub potentially sensative information from the AA data files, ie: variable names and such
- Are the data we match from RMP fundamentally different from the remaining RMP and remaining AA data? Is is representative?
- Is there a difference in tags and characteristics by matched and unmatched professors?
- Schedule meeting with stats people, get help on regression
- Calculate standard deviation of student interest
- Add variables for presence of word "accent" in comments
- Add variables for presence of words indicating a TA in comments
- Validate course number, ie: presence of upper-level course
- Match with web of science, ie: historiacl excellence vs. recent excellence
- Add more concise documentation, both changing code to be more expressive, and adding text
- validate gender matching using RMP comments


## Data Processing

First, we will load our data and perform some preprocessing. *aadata*: Contains combined dataset of Academic Analytics, Carnegie Classifications, and Rate My Professor 

Preprocessing Steps of AA data:

1. Drop those with null degree year
2. Remove those whom have only 1 review. (prehaps reconsider threshold?)
3. Remove those for which we could not assign male or female (UNK, INI, UNI, NA)
4. Assign an *"interdisciplinary"* variable to those with more than one record
5. Randomly select one record from those that appear as interdisciplinarity. Remove the others
5. Create new *"pubcount"* variableâ€”the sum of both the article and conference count. 
6. Normalize each research production variable by the mean of the level 4 discipline
7. Invert the *"easiness"* variable, such that 5 is easy and 1 is difficult.
8. Refactor *CC.CONTROL* and *CC.LOCALE* variables to a more friendly format
```{r, message=FALSE, warning=FALSE}
# Setup: install packages
library(ggplot2)

# Setup: load data
aadata <- readr::read_csv("~/Dropbox/AAWorkspace/AcademicAnalytics_RateMyTeacher_USNews_Carnegie_level4_VincentGender_Normalized.csv", col_types = cols(DegreeYear = col_integer(), X = col_skip(), X1 = col_skip()))


# Drop where degree year is NA or null
aadata <- aadata[!is.na(aadata$DegreeYear) & !is.null(aadata$DegreeYear) , ]

# Drop those with only 1 review
aadata <- aadata[aadata$COUNT > 1 & !is.na(aadata$RMT.Overall.mean), ]

# Drop those for whom we could not assign gender
aadata <- aadata[aadata$vincent_gender %in% c("M", "F"), ]

# Create another dataset, but this one where the authors are randomly selected from each group. Does this 
# significantly change our analysis?
library(dplyr)
aadata <- aadata %>% 
  group_by(personid) %>% 
  mutate(interdisciplinary = length(personid) > 1)
         
# Select randomly from those that appear as interdisciplinary
aadata <- aadata %>% group_by(personid) %>% sample_n(size = 1)

# Create new "pubcount variable" which is the sunm of articles and conference papers
aadata$pubcount <- aadata$articlecount + aadata$confproccount

# Now lets noramlize each of these values by their level4 disicplines...
aadata <- aadata %>%
    group_by(Level2ID) %>%
    mutate(norm_citationcount = citationcount / mean(citationcount), 
           norm_pubcount = pubcount / mean(pubcount))

# Invert easiness, such that 5 is very easy, and 1 is very difficult
aadata$RMT.Easiness.mean = 6 - aadata$RMT.Easiness.mean

# Refactor the variable concerning public/private control of uniersity
aadata$CC.CONTROL <- plyr::mapvalues(aadata$CC.CONTROL, c(1, 2), c("public", "private"))

# Refactor variable concerning size of university
aadata$CC.LOCALE_SIZE <- plyr::mapvalues(aadata$CC.LOCALE, 
                              c(11, 21, 31, 41, 12, 22, 32, 42, 13, 23, 33), 
                              c(rep("large", 4), rep("medium", 4), rep("small", 3)))

# Extract percentage value form the selectivity from US News and World Report
aadata$USNEWS.AcceptanceRate <- as.numeric(gsub("%", "", aadata$USNEWS.AcceptanceRate )) / 100
```

We will also be loading the comments data. *comments* contains all comments for professors matched between AA and RMP. We are doing a few things to extract variables from the comments file. 

1. We extract the "number" from the course number variable, containing a string manually entered by users
2. Determine if the course number is likely from an "upper" or a "lower" level course (ie: freshman/sophomore vs. junior/senior/graduate)
3. Extract and refactor the "student interest" variable from RMP
4 Convert student interest to a numeric ordinal variable, such that 1 = "Low", and 5 = "It's my life"
5. Calculate new variables *proportion_upper*, containing the proportion of likely upper-level courses taught by a professor
6. Create new *average_interest* variable containing the average interest of the numeric interest values for a professor
7. Merge new variables with the aadata table

```{r, message=FALSE, warning=FALSE}
comments <- read_csv("~/Dropbox/AAWorkspace/aa_professors_rmp_comments_aa_dates.csv")

# Define function to extract course number
extract_course_number <- function(course_string) {
   as.numeric(unlist(gsub("[^0-9]", "", course_string)))
}

# Define function to check whether data is upper level or not
is_upper_level <- function(course_num) {
  char_num = substr(as.numeric(course_num), 1, 1)
  if (is.na(char_num) | char_num == "1" | char_num == "2") {
    return(0)
  } else {
    return(1)
  }
}

# keeping the heuristic that numbers starting with 1 or 2 are lower level, while those beginning with 3+ are upper level
comments$course_numer <- sapply(comments$Course, extract_course_number)
comments$course_is_upper_level <- sapply(comments$course_numer, is_upper_level)

# Now lets also add an "interest measure"  for the student measure. We will give a number value to each "level" 
# of the interest, and find the average of all of the comments for each professor
comments$Interest <- factor(comments$Interest, c("N/A", "Low", "Meh", "Sorta interested", "Really into it", "It's my life"), ordered=TRUE)
factor_nums <- data.frame(factor = levels(comments$Interest), interest_value = c(NA, 1:5))
comments <- merge(comments, factor_nums, by.x = "Interest", by.y = "factor", all.x = TRUE)

detach("package:dplyr", unload=TRUE)
library(dplyr)
professor_data <- comments %>% 
  group_by(RMT.ProfessorID) %>% 
  summarise(
    num_upper_course_reviews = sum(course_is_upper_level),
    average_interest  = mean(interest_value, rm.na = TRUE)
  )
professor_data$teaches_upper <- professor_data$num_upper_course_reviews > 0

aadata <- merge(aadata, professor_data, all.x=TRUE)

aadata$proportion_upper <- aadata$num_upper_course_reviews / aadata$COUNT
```


## Analysis of Tags: What makes a "good" professor?
So before we get into the weeds with our analysis of the relationship between research performance and overall quality, we should exactly what this overall quality *means*. What makes a "good professor" for RMP raters? This is important, because we need to establish what we mean by quality. Fortunately, RMP allows users to apply tags to researchers with certain traits, and with these tags we can get an idea of what raters this is important. 

In this code block, we extract and format the tags from the dataset. These tags are contained in a semicolon-seperated list of strigs in the original dataframe. I have only collected tags at the level of the professor, and not the comment. I thus do not have any idea about how many raters assigned a tag to a professer, just that the tag *was* assigned. 
```{r}
# split list of strings
tags <- strsplit(aadata$RMT.Tags, "; ")

# Trim extra whitespace form tags
aadata$tag_list <- sapply(tags, function(t) {
  sapply(t, function(x) {
    return(trimws(x, "r"))
  })
})

# get unique tags
unq <- unique(unlist(aadata$tag_list))

# Setup necessary variables for following loop
map <- data.frame(tag = unq[!is.na(unq)], mapping = 1:(length(unq) - 1))
frame <- as.data.frame(matrix(0, ncol = dim(map)[1], nrow=dim(aadata)[1]))
colnames(frame) <- map$tag

# Create a n X t matrix, where n is the number of records (professors) and t is the number of unique tags. Each 
# cell of this matrix contains a 1 if that professor was given that tag by a user
for (i in 1:dim(aadata)[1]) {
  tags <- unlist(aadata$tag_list[i])
  for (t in tags) {
    if(!is.na(t)) {
      loc = map[map$tag == t, "mapping"]
      frame[i, loc] <-  1
    }
  }
}

# Now that we have these, we can rbind with the other features. 
quality_regdata <- cbind(overall = aadata$RMT.Overall.mean, gender = aadata$vincent_gender, frame)
```

Now we can run a multiple regression, using the overall quality as the dependent variable, and all the tags as the independent variable. With this, we can assess the contributions of each tag, and determine tags are most associated with the high and low overall quality. 
```{r}
# fit the model, but for now ignore gender
overall_tag_fit <- lm(overall ~ . -gender ,
                  data = quality_regdata
)
summary(overall_tag_fit)
```

And now we can use a function from the *caret* R package to get a sense of which variables contribute the most to the r^2 value we observe in the previous table. In essence, this tells us the importance of each variable. Higher ranks mean more important, lower ranks mean less important. 
```{r rows.print=100}
library(caret)
imp = varImp(overall_tag_fit, scale = FALSE)
imp[order(-imp$Overall), , drop = FALSE]
```

So, cross-referencing both tables, the ranking of the most important terms ***positively*** correlated with overall quality are:

1. Respected
2. Amazing Lectures
3. Gives good feedback
4. Caring
5. Clear grading criteria
6. Inspirational
7. Hilarious
8. EXTRA CREDIT (non-significant)


And the ranking of the most important ***negatively*** correlated terms is as follows,

1. LECTURE HEAVY
2. LOTS OF HOMEWORK
3. Get ready to read
4. GROUP PROJECTS
5. BEWARE OF POP QUIZZES
6. SO MANY PAPERS
7. TEST HEAVY
8. Skip class? you won't pass
9. ACCESSIBLE OUTSIDE CLASS (non-significant)
10. PARTICIPATION MATTERS (non-significant)


In future work, we can do some analysis of the text of the comments themselves, but this becomes exponentially more complicated, and so for preliminary analysis, we will proceed with an understand of overall quality ratings constituted by these tags. 

Future work might also examine differences in tags and comments between different categoeis of professors, such as by professor gender, rank, undersity of employment, or discipline. For example, we can create a quick table to serve as a quick exmaple of how these tags might differ between men and women,
- TODO: Visualize using bar-chart
```{r}
library(tableone)
listVars <- colnames(quality_regdata)
listVars <- listVars[listVars != "gender"]
catVars = c("gender")
table1 <- CreateTableOne(listVars, quality_regdata, catVars, strata = c("gender"))
table1
```


## Analysis of Overall Quality and Other Variables

Now we need to format the data that we will use for the final regression. the *ready_data* variable contains this data. Most columns are pulled directly from the the original *aadata* dataframe. We however create the following variables as a more clean and useful versions of the original research output data. 

- *citedness*: 0 if no citations. 1 if citations between 1st and 50th percentile of those in their high-level discipline. 2 if above 50th percentile of those with at least one citation in discipline
- *output*: 0 if no publications. 1 if publications between 1st and 50th percentile of those with at least 1 publication in their high-level discipline. 2 if above 50th percentile
- *grantiness*: 0 if no grants. 1 if grantcount between 1st and 50th percentile of those with at least 1 grant in their high-level discipline. 2 if above 50th percentile.
- *bookiness*: 0 if no books. 1 if bookcount between 1st and 50th percentile of those with at least 1 book 2 if above 50th percentile.
- *awardiness*: 0 if no awards. 1 if awardcount between 1st and 50th percentile of those with at least 1 award. 2 if above 50th percentile.
- *excellence*: True if at least one of the following variables contains a value of 2: citedness, output, grantiness, bookiness, awardiness
```{r}
exc_threshold <- 0.90
# perhaps we can adjust this to use the median citation count within a given discipline, perhaps at L1 or L2?
citation_med = quantile(subset(aadata, norm_citationcount > 0)$norm_citationcount, 0.90)
citedness = factor(with(aadata, ifelse(citationcount == 0, 0, ifelse(norm_citationcount <= citation_med, 1, 2))))

production_med = median(subset(aadata, pubcount > 0)$norm_pubcount)
output = factor(with(aadata, ifelse(pubcount == 0, "None", ifelse(norm_pubcount <= production_med, "Normal", "High"))))

book_med = median(subset(aadata, bookcount > 0)$bookcount)
bookiness = factor(with(aadata, ifelse(bookcount == 0, 0, ifelse(bookcount <= book_med, 1, 2))))

grant_med = median(subset(aadata, grantcount > 0)$grantcount)
grantiness = factor(with(aadata, ifelse(grantcount == 0, 0, ifelse(grantcount <= grant_med, 1, 2))))

award_med = median(subset(aadata, awardcount > 0)$awardcount)
awardiness = factor(with(aadata, ifelse(awardcount == 0, 0, ifelse(awardcount <= award_med, 1, 2))))

excellence = factor(citedness == 2 | output == 2 | bookiness == 2 | grantiness == 2 | awardiness == 2)
  
ready_data <- data.frame(id = aadata$personid, 
                         overall = aadata$RMT.Overall.mean,
                         overall_sd = aadata$RMT.Overall.sd,
                         easiness = aadata$RMT.Easiness.mean,
                         easiness_sd = aadata$RMT.Easiness.sd,
                         interdisciplinary = factor(aadata$interdisciplinary),
                         review_count = aadata$COUNT,
                         excellence,
                         award_count = aadata$awardcount,
                         avg_interest = aadata$average_interest,
                         bookiness,
                         awardiness,
                         grantiness,
                         # Convert age into something that we can more easily think about, ie: scientific age
                         age = 2016 - aadata$DegreeYear,
                         gender = factor(aadata$vincent_gender),
                         citedness,
                         output,
                         discipline = relevel(factor(aadata$Level.4), ref = 4),
                         uni_type = relevel(factor(aadata$CC.BASIC2015), ref = 2),
                         uni_control = factor(aadata$CC.CONTROL),
                         uni_locale_size = relevel(factor(aadata$CC.LOCALE_SIZE), ref = 2),
                         prop_upper = aadata$proportion_upper,
                         acceptance_rate = aadata$USNEWS.AcceptanceRate
)
```


Now we can finally fun the regression we have all been waiting for! In this case, the overal quality measure is used as the dependent variable, and the remainder are the independent vairables. Some basic interactions are also included here. In this case, there are several variables that are factors; for these categorical variables, the regression compares the effect against that of a pre-seldcted factor. 

- For the discipline variable, we compare against the Natural Sciences
- For Each output, citedness, bookiness, grantiness, and awardiness, we compare against 0, ie: value of zero for the given research performance indicator.
- For unviersity type, we compare to R1 institutions
- For gender, we compare against women
- for unvieristy control, we compare against private
- For university locale, we compare against medium-sized universities

```{r}
fit <- lm(overall ~ 
            # Teacherl Characteristics
            gender +
            age +
            # Course characteirstics
            easiness +
            easiness_sd +
            avg_interest +
            review_count +
            prop_upper +
            # Research characteristics
            citedness +
            output +
            bookiness +
            grantiness +
            awardiness +
            # Disciplinary differences
            discipline +
            interdisciplinary +
            # University
            uni_type +
            uni_control +
            uni_locale_size + 
            acceptance_rate +
            # interactions
            discipline * excellence +
            gender * excellence +
            uni_type * excellence,
          data=ready_data)
summary(fit)
```

As before, we can pair the output of this regression with a calculation of variable importance. 
```{r rows.print=100}
library(caret)
imp = varImp(fit, scale = FALSE)
imp[order(-imp$Overall), , drop = FALSE]
```

Already, we see that a few variables massively outperform the others in terms of contributing to the r^2. Here is a ranking of the most important variables that contribute positively to the overall teaching quality. In this case, I will only list the first few positively-correlated variables, as there are a large number of non-significant and somewhat inconsequential effects. 

1. easiness (easier the class, higher the rating)
2. avg_interest (higher the user's stated "interest" in the course, higher the review)
3. genderM (male professors rated higher)
4. disciplineHumanities (humanities professors get higher ratings than natural sciences)
5. prop_upper (teaching more advanced level courses means higher ratings)
6. review_count (more reviews tends to mean more positive ratings overall)
7. Awardiness2 (excellence in awards means higher scores)


And again, we can do the same with the negatively correlated variables

1. age (older the professor, lower the score)
2. easiness_sd (more diversity in easiness reviews, the lower the quality
3. interdisciplinaryTRUE (having more than 1 aa record improves makes score lower, warrants further investigation)
4. uni_controlpublic (professors at public universities get lower ratings)
5. grantiness2 (excellence in grants means lower scores)

## Descriptive analysis and Summary Graphs

### Density Plots of overall quality

First, lets make a quick functiuon that will make it easy to add the size of groups to the subtitle of each graph
```{r}
library(stringr)
generate_n_string <- function(var) {
  tab <- table(var)
  lab <- names(tab)
  vals <- paste(tab)
  str <- ""
  for (i in 1:length(lab)) {
    str <- paste(str, "n(", lab[i], ") = ", vals[i], ";")
  }
  return(str_wrap(str, 100))
}
```

And now we can begin creating plots. I am intentionally doing each of thees manually, rather than writing a nice function to quickly plot all density plots. This way, we have more careful control over each plot in the future. 
```{r}
ggplot(ready_data, aes(overall, colour=gender)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Gender",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$gender))
```

```{r}
ggplot(ready_data, aes(overall, colour=citedness)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Citedness",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$citedness)
       )
```

```{r}
ggplot(ready_data, aes(overall, colour=output)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Publication Output",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$output)
       )
```


```{r}
ggplot(ready_data, aes(overall, colour=awardiness)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Awardiness",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$awardiness)
       )
```

```{r}
ggplot(ready_data, aes(overall, colour=grantiness)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Grantiness",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$grantiness)
       )
```

```{r}
ggplot(ready_data, aes(overall, colour=bookiness)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Bookiness",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$bookiness)
       )
```


```{r}
ggplot(ready_data, aes(overall, colour=discipline)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Discipline",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$discipline)
       )
```

```{r}
ggplot(ready_data, aes(overall, colour=interdisciplinary)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by status of interdisciplinary",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$interdisciplinary))
```

```{r}
ggplot(ready_data, aes(overall, colour=uni_type)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by University Type",
       xlab = "Overall Quality",
       subtitle = generate_n_string(ready_data$uni_type))
```

```{r}
ggplot(ready_data, aes(overall, colour=uni_control)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Quality by Univeristy Control (public/private)",
       subtitle = generate_n_string(ready_data$uni_control)
       )
```

### Distribution of Age
```{r}
ggplot(ready_data, aes(age, color = gender)) +
  geom_density() +
  xlim(0, 70) +
  theme_bw() +
  labs(title="Density of Age by gender")
```

```{r}
ggplot(ready_data, aes(age, color = discipline)) +
  geom_density() +
  xlim(0, 70) +
  theme_bw() +
  labs(title="Density of Age by Discipline")
```

```{r}
ggplot(ready_data, aes(age, color = citedness)) +
  geom_density() +
  xlim(0, 70) +
  theme_bw() +
  labs(title="Density of Age by Citedness") 
```

```{r}
ggplot(ready_data, aes(age, color = uni_type)) +
  geom_density() +
  xlim(0, 70) +
  theme_bw() +
  labs(title="Density of Age by Univeristy Type") 
```

### Density by review count: who gets rated the most? or Who uses RMP the most?

```{r}
ggplot(ready_data, aes(review_count, color = gender)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() +
  labs(title="Density of Number of Student Reviews by Gender")
```

```{r}
ggplot(ready_data, aes(review_count, color = discipline)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() +
  labs(title="Density of Number of Student Reviews by Discipline")
```

```{r}
ggplot(ready_data, aes(review_count, color = citedness)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() +
  labs(title="Density of Number of Student Reviews by Citedness")
```

```{r}
ggplot(ready_data, aes(review_count, color = uni_type)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() +
  labs(title="Density of Number of Student Reviews by Univeristy Type")
```

### Distribution of Easiness

```{r}
ggplot(ready_data, aes(easiness, color = gender)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Easinesst Reviews by gender")
```

```{r}
ggplot(ready_data, aes(easiness, color = discipline)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Easinesst Reviews by discipline")
```

```{r}
ggplot(ready_data, aes(easiness, color = uni_type)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Easinesst Reviews by Univeristy Type")
```

```{r}
ggplot(ready_data, aes(easiness, color = citedness)) +
  geom_density() +
  theme_bw() +
  labs(title="Density of Easinesst Reviews by Citedness")
```


```{r}
ggplot(ready_data, aes(review_count, color = discipline)) +
  geom_density() +
  xlim(0, 100) +
  theme_bw() +
  labs(title="Density of Number of Student Reviews by Univeristy Control (public/private)",
       xlab = "Overall Quality") 
```



### relationships between overall quality and continous variables


```{r}
# R- Squared- 0.189
d <- ggplot(ready_data, aes(easiness, overall))
  
d + geom_hex(bins=10) + geom_smooth(method='lm', color="red", level=0.95, se=TRUE) +
  scale_fill_gradientn(colours=c("white","blue"),name = "Frequency",na.value=NA) + 
  annotate("text", label="r^2=0.189", x=3.5, y=1.8, size=4.5) +
  labs(title = "Hexbin Plots of Easiness vs. Overall",
       subtitle = "Cell color represents frequency of records in that cell. Red line plots goodness of fit")
```


```{r}
d <- ggplot(ready_data, aes(age, overall))
d + geom_hex(bins=10) + geom_smooth(method='lm', color="red", level=0.95, se=TRUE) +
  scale_fill_gradientn(colours=c("white","blue"),name = "Frequency",na.value=NA) +
  annotate("text", label="r^2=0.0303", x=55, y=1.8, size=4.5) +
  labs(title = "Hexbin Plots of Age vs. Overall",
       subtitle = "Cell color represents frequency of records in that cell. Red line plots goodness of fit")
```

```{r}
ggplot(ready_data, aes(avg_interest, overall)) + 
  geom_hex(bins=10) + 
  geom_smooth(method='lm', color="red", level=0.95, se=TRUE) +
  scale_fill_gradientn(colours=c("white","blue"),name = "Frequency",na.value=NA) +
  labs(title = "Hexbin Plots of Overall and Average Interest of student reviews",
       subtitle = "Cell color represents frequency of records in that cell. Red line plots goodness of fit")
```

```{r}
ggplot(ready_data, aes(prop_upper, overall)) + 
  geom_hex(bins=10) + 
  geom_smooth(method='lm', color="red", level=0.95, se=TRUE) +
  scale_fill_gradientn(colours=c("white","blue"),name = "Frequency",na.value=NA) +
  labs(title = "Hexbin Plots of Overall Quality and Proportion of Upper-Level Courses",
       subtitle = "Cell color represents frequency of records in that cell. Red line plots goodness of fit")
```


## Boxplots of Gender

```{r}
ggplot(ready_data, aes(citedness, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Citedness")
```

```{r}
ggplot(ready_data, aes(output, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Publication Output")
```

```{r}
ggplot(ready_data, aes(awardiness, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Awardiness")
```

```{r}
ggplot(ready_data, aes(bookiness, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Bookiness")
```

```{r}
ggplot(ready_data, aes(grantiness, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Grantiness")
```


```{r}
ggplot(ready_data, aes(discipline, overall, fill=gender)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Gender and Grantiness")
```

### Boxplots of Discipline

```{r}
ggplot(ready_data, aes(discipline, overall, fill=citedness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Citedness")
```

```{r}
ggplot(ready_data, aes(discipline, overall, fill=output)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Grantiness")
```

```{r}
ggplot(ready_data, aes(discipline, overall, fill=bookiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Bookiness")
```

```{r}
ggplot(ready_data, aes(discipline, overall, fill=awardiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Awardiness")
```


```{r}
ggplot(ready_data, aes(discipline, overall, fill=grantiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Grantiness")
```

```{r}
ggplot(ready_data, aes(discipline, overall, fill=interdisciplinary)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Discipline and Grantiness")
```

# Boxplots of Univeristy Type
```{r}
ggplot(ready_data, aes(uni_type, overall, fill=citedness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of University Tyoe and Citedness")
```

```{r}
ggplot(ready_data, aes(uni_type, overall, fill=output)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Univeristy Type and Publication Output")
```

```{r}
ggplot(ready_data, aes(uni_type, overall, fill=awardiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Univeristy Type and Awardiness")
```

```{r}
ggplot(ready_data, aes(uni_type, overall, fill=grantiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Univeristy Type and Grantiness")
```

```{r}
ggplot(ready_data, aes(uni_type, overall, fill=bookiness)) + 
  geom_boxplot() +
  labs(title = "Boxplots of Univeristy Type and Bookiness")
```

Beware of small sample sizes however,
```{r}
table(ready_data$uni_type, ready_data$grantiness)
```

